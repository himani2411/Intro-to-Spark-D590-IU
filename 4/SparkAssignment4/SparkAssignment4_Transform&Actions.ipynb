{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13505c2e",
      "metadata": {
        "id": "13505c2e"
      },
      "source": [
        "# Assignment 4\n",
        "by Himani Anil Deshpande"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "70aa21f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70aa21f7",
        "outputId": "e5975ab8-c878-44c1-afa3-dbf783c4a346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 40 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 81 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 92 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 102 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 112 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 122 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 133 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 153 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 163 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 174 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 184 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 194 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 198 kB 11.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j\n",
            "Successfully installed py4j-0.10.9.3\n"
          ]
        }
      ],
      "source": [
        "pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry-n3F9aj53R",
        "outputId": "d06694e6-239f-4ec3-c288-7cba087933de"
      },
      "id": "ry-n3F9aj53R",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 38 kB/s \n",
            "\u001b[?25hRequirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=ee26c12c874e6ada4c92f46c4d28cd1c96d135c1fc8cc33cc9f302587b591994\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec62cec",
      "metadata": {
        "id": "eec62cec"
      },
      "source": [
        "Connecting to Spark Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c7265b0f",
      "metadata": {
        "id": "c7265b0f"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import DoubleType, IntegerType, DateType\n",
        "from pyspark.sql.functions import col, asc,desc\n",
        "import json\n",
        "import csv\n",
        "from io import StringIO\n",
        "from pyspark.sql import HiveContext\n",
        "sc = SparkContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1cd8d8",
      "metadata": {
        "id": "af1cd8d8"
      },
      "source": [
        "Load fake_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "249b40b6",
      "metadata": {
        "id": "249b40b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# datafile = \"file:///Users/himanideshpande/miniforge3/envs/ENV_SPARK/SparkInstallation/spark-3.2.1-bin-hadoop2.7/IPYNB/Fake_data.csv\"\n",
        "datafile = \"/content/Fake_data.csv\"\n",
        "# input_json = sc.textFile(datafile)\n",
        "def loadRecord(line):\n",
        "    \"\"\"Parse a CSV line\"\"\"\n",
        "    input = StringIO(line)\n",
        "    reader = csv.DictReader(input, fieldnames=[\"index\",\"Birth_Country\",\"Email\",\"First_Name\",\"Income\",\"Job\",\"Last_name\",\"Loan_Approved\",\"SSN\"])\n",
        "    return next(reader)\n",
        "\n",
        "input_data = sc.textFile(datafile).map(loadRecord)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "22a407a3",
      "metadata": {
        "id": "22a407a3"
      },
      "outputs": [],
      "source": [
        "rdd = sc.parallelize(input_data.collect())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rdd.collect()\n",
        "\n",
        "spark = SparkSession(sc)"
      ],
      "metadata": {
        "id": "xhmj5xJtnoeX"
      },
      "id": "xhmj5xJtnoeX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =  rdd.toDF()"
      ],
      "metadata": {
        "id": "-MM_cjlym-2X"
      },
      "id": "-MM_cjlym-2X",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTjDoRBiq6p6",
        "outputId": "cd5306ec-25b9-48f1-c7aa-47762f3b3571"
      },
      "id": "CTjDoRBiq6p6",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Birth_Country: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- First_Name: string (nullable = true)\n",
            " |-- Income: string (nullable = true)\n",
            " |-- Job: string (nullable = true)\n",
            " |-- Last_name: string (nullable = true)\n",
            " |-- Loan_Approved: string (nullable = true)\n",
            " |-- SSN: string (nullable = true)\n",
            " |-- index: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('Income', col('Income').cast(IntegerType()))"
      ],
      "metadata": {
        "id": "5V9H04Pmr81J"
      },
      "id": "5V9H04Pmr81J",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYhcjuoYsOqi",
        "outputId": "b3bc8b38-a311-4f94-91c7-e38ddfd7ae0e"
      },
      "id": "MYhcjuoYsOqi",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Birth_Country: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- First_Name: string (nullable = true)\n",
            " |-- Income: integer (nullable = true)\n",
            " |-- Job: string (nullable = true)\n",
            " |-- Last_name: string (nullable = true)\n",
            " |-- Loan_Approved: string (nullable = true)\n",
            " |-- SSN: string (nullable = true)\n",
            " |-- index: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9080492e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9080492e",
        "outputId": "def80ee9-abe9-447b-e911-3497aa3ec01b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(rdd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bd7d25",
      "metadata": {
        "id": "a4bd7d25"
      },
      "source": [
        "Question 1. \n",
        "Find birth country which has highest amount of people "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4f43c008",
      "metadata": {
        "id": "4f43c008"
      },
      "outputs": [],
      "source": [
        "highest_df = df.groupBy(\"Birth_Country\").count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highest_df.orderBy(col(\"count\").desc()).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x-C-SvipOY5",
        "outputId": "e5cf77ab-32ab-4880-9e23-a228062c5ed0"
      },
      "id": "-x-C-SvipOY5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|Birth_Country|count|\n",
            "+-------------+-----+\n",
            "|        Korea|   91|\n",
            "+-------------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "671889c7",
      "metadata": {
        "id": "671889c7"
      },
      "source": [
        "Question 2\n",
        "Find average income of people who are born in united states of america "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e4c832b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4c832b9",
        "outputId": "355f924b-1b57-4a1d-84ab-70346668f36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|       Birth_Country|       avg(Income)|\n",
            "+--------------------+------------------+\n",
            "|United States of ...|208759.82352941178|\n",
            "+--------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df['Birth_Country'] =='United States of America').groupBy('Birth_Country').avg('Income').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3 How many people has income over 100,000 but their loan is not approved. "
      ],
      "metadata": {
        "id": "jjvOfEDHsbAo"
      },
      "id": "jjvOfEDHsbAo"
    },
    {
      "cell_type": "code",
      "source": [
        "df_count_income_high = df.filter((df.Income >100000) & (df.Loan_Approved == False))"
      ],
      "metadata": {
        "id": "H37tRTDzsec7"
      },
      "id": "H37tRTDzsec7",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_count_income_high.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhFto79huEpn",
        "outputId": "3a1cddb8-14f7-4e9c-ae97-c8bde391ad2e"
      },
      "id": "AhFto79huEpn",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4009"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 Find top 10 people with highest income in United States of america. (Print their names, income and jobs)"
      ],
      "metadata": {
        "id": "zbagZCdPuL_4"
      },
      "id": "zbagZCdPuL_4"
    },
    {
      "cell_type": "code",
      "source": [
        "top_paid = df.filter(df['Birth_Country'] =='United States of America').orderBy(col(\"Income\").desc())"
      ],
      "metadata": {
        "id": "3h9GkFtauRKp"
      },
      "id": "3h9GkFtauRKp",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_paid.select(\"First_Name\", \"Last_name\",\"Job\", \"Income\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkxdeQffvAbq",
        "outputId": "e3f33732-ad1a-4d83-9557-2d539db7828e"
      },
      "id": "IkxdeQffvAbq",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+--------------------+------+\n",
            "|First_Name|Last_name|                 Job|Income|\n",
            "+----------+---------+--------------------+------+\n",
            "|    Alyssa|   Miller|Amenity horticult...|482588|\n",
            "|    Hunter|    Walls|Psychologist, pri...|468946|\n",
            "|      Rose|Henderson|Adult guidance wo...|426115|\n",
            "|  Danielle|  Leonard|Furniture conserv...|389810|\n",
            "|     Terry|    Klein|       Meteorologist|380410|\n",
            "|     Cindy|   Newton|Research scientis...|370322|\n",
            "|     Scott| Mitchell|       Art therapist|368913|\n",
            "|   Christy| Sandoval|      Engineer, land|355150|\n",
            "|     Kelly| Reynolds|           Press sub|341448|\n",
            "|  Kristina|    Smith|           Herbalist|338804|\n",
            "+----------+---------+--------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5 How many number of distinct jobs are there?"
      ],
      "metadata": {
        "id": "hCYV1stTvnkU"
      },
      "id": "hCYV1stTvnkU"
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"Job\").distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-lO1PD5vmky",
        "outputId": "7eebc92c-7300-4505-f759-b3a94593dc20"
      },
      "id": "v-lO1PD5vmky",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "640"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6 How many writers earn less than 100,000? "
      ],
      "metadata": {
        "id": "obTBXOKav9_f"
      },
      "id": "obTBXOKav9_f"
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((df.Income <100000) & (df.Job == 'Writer')).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxCjPtcVwDh6",
        "outputId": "3072e0c4-4b00-4f3c-8020-81528e84d745"
      },
      "id": "kxCjPtcVwDh6",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "https://www.datasciencemadesimple.com/distinct-value-of-a-column-in-pyspark/#:~:text=Distinct%20value%20of%20the%20column%20in%20pyspark%20is%20obtained%20by,value%20of%20those%20columns%20combined."
      ],
      "metadata": {
        "id": "UYwtpk77UAmM"
      },
      "id": "UYwtpk77UAmM"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "SparkAssignment4_Transform&Actions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}